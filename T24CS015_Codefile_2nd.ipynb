{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saucymukhim/Chisur-Academy-Test-01/blob/main/T24CS015_Codefile_2nd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EFFICIENTNETV2 + TRANSFORMER HEAD**"
      ],
      "metadata": {
        "id": "rLu1SWxe6oSU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION 1: SETUP & INSTALLATION"
      ],
      "metadata": {
        "id": "nUruxtt8-y25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def card(msg, bg):\n",
        "    display(HTML(f\"<div style='background:{bg};padding:14px;border-radius:10px;\"\n",
        "                 \"color:white;font-family:Segoe UI;box-shadow:0 4px 14px #0005'>\"\n",
        "                 f\"<b>{msg}</b></div>\"))\n",
        "\n",
        "card(\" Connecting to Google Driveâ€¦\", \"linear-gradient(135deg,#232526,#414345)\")\n",
        "drive.mount(\"/content/drive\")\n",
        "card(\" Drive mounted at /content/drive\", \"linear-gradient(135deg,#11998e,#38ef7d)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "Atu7w2D0I5kC",
        "outputId": "39140dc0-d2c0-43cb-8614-8d261ed7b883"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:linear-gradient(135deg,#232526,#414345);padding:14px;border-radius:10px;color:white;font-family:Segoe UI;box-shadow:0 4px 14px #0005'><b> Connecting to Google Driveâ€¦</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:linear-gradient(135deg,#11998e,#38ef7d);padding:14px;border-radius:10px;color:white;font-family:Segoe UI;box-shadow:0 4px 14px #0005'><b> Drive mounted at /content/drive</b></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "path = \"/content/drive/MyDrive/SaucyDataset\"\n",
        "\n",
        "display(HTML(f\"<div style='background:linear-gradient(135deg,#141e30,#243b55);\"\n",
        "             \"padding:14px;border-radius:10px;color:white;\"\n",
        "             \"font-family:Segoe UI;box-shadow:0 4px 14px #0005'>\"\n",
        "             f\"<b>ğŸ“ Dataset directory</b><br><code>{path}</code></div>\"))\n",
        "\n",
        "%cd {path}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "aIzYesTfJBVK",
        "outputId": "8497eb67-40a1-4150-f6c3-95fc08ed25cc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:linear-gradient(135deg,#141e30,#243b55);padding:14px;border-radius:10px;color:white;font-family:Segoe UI;box-shadow:0 4px 14px #0005'><b>ğŸ“ Dataset directory</b><br><code>/content/drive/MyDrive/SaucyDataset</code></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SaucyDataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages for the environment\n",
        "!pip uninstall torch torchvision torchaudio -y\n",
        "!pip install torch torchvision torchaudio --no-cache-dir\n",
        "!pip install --upgrade -q timm scikit-learn seaborn rich\n",
        "!pip install grad-cam\n",
        "!pip install optuna\n",
        "!pip install pytorch-grad-cam\n",
        "!pip install albumentations\n",
        "!pip install torchmetrics\n",
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "lN-H4MIKA84e",
        "outputId": "9e572c5a-91b2-455a-863d-38eb336beb0d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.9.0+cu126\n",
            "Uninstalling torch-2.9.0+cu126:\n",
            "  Successfully uninstalled torch-2.9.0+cu126\n",
            "Found existing installation: torchvision 0.24.0+cu126\n",
            "Uninstalling torchvision-0.24.0+cu126:\n",
            "  Successfully uninstalled torchvision-0.24.0+cu126\n",
            "Found existing installation: torchaudio 2.9.0+cu126\n",
            "Uninstalling torchaudio-2.9.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "Collecting torch\n",
            "  Downloading torch-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (31 kB)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.25.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Collecting cuda-bindings==12.9.4 (from torch)\n",
            "  Downloading cuda_bindings-12.9.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Collecting nvidia-nvshmem-cu12==3.4.5 (from torch)\n",
            "  Downloading nvidia_nvshmem_cu12-3.4.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.6.0 (from torch)\n",
            "  Downloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch) (1.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Downloading torch-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl (915.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m915.7/915.7 MB\u001b[0m \u001b[31m230.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cuda_bindings-12.9.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m232.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m253.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m246.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m254.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m388.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m215.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m383.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m142.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.4.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (139.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.1/139.1 MB\u001b[0m \u001b[31m159.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m286.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (188.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.3/188.3 MB\u001b[0m \u001b[31m187.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.25.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m188.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m205.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, cuda-bindings, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvshmem-cu12\n",
            "    Found existing installation: nvidia-nvshmem-cu12 3.3.20\n",
            "    Uninstalling nvidia-nvshmem-cu12-3.3.20:\n",
            "      Successfully uninstalled nvidia-nvshmem-cu12-3.3.20\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: cuda-bindings\n",
            "    Found existing installation: cuda-bindings 12.9.5\n",
            "    Uninstalling cuda-bindings-12.9.5:\n",
            "      Successfully uninstalled cuda-bindings-12.9.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cuda-python 12.9.5 requires cuda-bindings~=12.9.5, but you have cuda-bindings 12.9.4 which is incompatible.\n",
            "fastai 2.8.6 requires torch<2.10,>=1.10, but you have torch 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cuda-bindings-12.9.4 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.4.5 nvidia-nvtx-cu12-12.8.90 torch-2.10.0 torchaudio-2.10.0 torchvision-0.25.0 triton-3.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cuda",
                  "torch",
                  "torchgen",
                  "torchvision",
                  "triton"
                ]
              },
              "id": "eb7c71b988914e0b859c162338fe34bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/310.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m310.0/310.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 2.33.0 requires rich<14,>=12.4.4, but you have rich 14.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting grad-cam\n",
            "  Downloading grad-cam-1.5.5.tar.gz (7.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from grad-cam) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from grad-cam) (11.3.0)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from grad-cam) (2.10.0)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.12/dist-packages (from grad-cam) (0.25.0)\n",
            "Collecting ttach (from grad-cam)\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from grad-cam) (4.67.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from grad-cam) (4.13.0.92)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from grad-cam) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from grad-cam) (1.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (2025.3.0)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=1.7.1->grad-cam) (1.3.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->grad-cam) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->grad-cam) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->grad-cam) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.1->grad-cam) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7.1->grad-cam) (3.0.3)\n",
            "Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Building wheels for collected packages: grad-cam\n",
            "  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grad-cam: filename=grad_cam-1.5.5-py3-none-any.whl size=44284 sha256=2d3895638b654367cfa5a9db5e60af28ea5f14508b1b6f95f05f4714c42cdb76\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/3b/09/2afc520f3d69bc26ae6bd87416759c820a3f7d05c1a077bbf6\n",
            "Successfully built grad-cam\n",
            "Installing collected packages: ttach, grad-cam\n",
            "Successfully installed grad-cam-1.5.5 ttach-0.0.3\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.7.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.18.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch-grad-cam (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pytorch-grad-cam\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (2.0.8)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations) (1.16.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations) (6.0.3)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.12.3)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations) (4.13.0.90)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (4.6.0)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (6.5.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.10.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=2.0.0->torchmetrics) (1.3.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.13.0.92)\n",
            "Requirement already satisfied: numpy>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os, json, random, warnings\n",
        "import torch, torch.nn as nn, torch.optim as optim, torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from torchvision import datasets, transforms\n",
        "import timm, cv2, optuna\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, average_precision_score, precision_recall_fscore_support\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torchmetrics import CalibrationError\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<div style='background:#020617;padding:10px;border-radius:8px;\"\n",
        "             \"color:#86efac;font-family:Segoe UI'>\"\n",
        "             \"ğŸ“¦ <b>Libraries imported successfully</b> â€” system ready</div>\"))\n"
      ],
      "metadata": {
        "id": "yzh6nIR6A_YW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3e8627a8-b0a5-41e0-ccdd-0aa12eefbda5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:10px;border-radius:8px;color:#86efac;font-family:Segoe UI'>ğŸ“¦ <b>Libraries imported successfully</b> â€” system ready</div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION 2: CONFIGURATION"
      ],
      "metadata": {
        "id": "RZPPjRR8BFto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Central configuration class\n",
        "class Config:\n",
        "    \"\"\"Configuration class for the bone fracture detection project.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.DATA_PATH = \"/content/drive/MyDrive/SaucyDataset\"\n",
        "        self.OUTPUT_DIR = \"/content/drive/MyDrive/SaucyDataset_Output\"\n",
        "        os.makedirs(self.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "        self.MODEL_NAME = 'tf_efficientnetv2_s.in1k'\n",
        "        self.IMAGE_SIZE = 256\n",
        "        self.BATCH_SIZE = 8\n",
        "        self.EPOCHS = 30\n",
        "        self.LEARNING_RATE = 1e-4\n",
        "        self.NUM_CLASSES = 2\n",
        "\n",
        "        self.D_MODEL = 256\n",
        "        self.NHEAD = 8\n",
        "        self.NUM_ENCODER_LAYERS = 4\n",
        "        self.DIM_FEEDFORWARD = 2048\n",
        "        self.DROPOUT = 0.1\n",
        "\n",
        "        self.K_FOLDS = 2\n",
        "        self.SEED = 42\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "CFG = Config()\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(f\"<div style='background:#020617;padding:10px;border-radius:8px;\"\n",
        "             \"color:#93c5fd;font-family:Segoe UI'>\"\n",
        "             f\"âš™ï¸ <b>Config loaded</b> | Device: <code>{CFG.device}</code></div>\"))\n"
      ],
      "metadata": {
        "id": "c6azka_2BKSo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c24c7ae2-2b30-45ef-b2f1-fa1f360998f9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:10px;border-radius:8px;color:#93c5fd;font-family:Segoe UI'>âš™ï¸ <b>Config loaded</b> | Device: <code>cuda:0</code></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION 3: DATA HANDLING & TRANSFORMATIONS"
      ],
      "metadata": {
        "id": "miHtK42fBbzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data handling & transformations\n",
        "class DataTransforms:\n",
        "    \"\"\"Class to handle data transformations for different phases (train, val, test, tta).\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_transforms(image_size, phase='train'):\n",
        "        if phase == 'train':\n",
        "            return transforms.Compose([\n",
        "                transforms.RandomResizedCrop(image_size),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomRotation(10),\n",
        "                transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                     [0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        elif phase in ['val', 'test']:\n",
        "            return transforms.Compose([\n",
        "                transforms.Resize(256),\n",
        "                transforms.CenterCrop(image_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                     [0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        elif phase == 'tta':\n",
        "            return [\n",
        "                transforms.Compose([\n",
        "                    transforms.Resize(256),\n",
        "                    transforms.CenterCrop(image_size),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                         [0.229, 0.224, 0.225])\n",
        "                ]),\n",
        "                transforms.Compose([\n",
        "                    transforms.Resize(256),\n",
        "                    transforms.CenterCrop(image_size),\n",
        "                    transforms.RandomHorizontalFlip(1.0),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                         [0.229, 0.224, 0.225])\n",
        "                ]),\n",
        "                transforms.Compose([\n",
        "                    transforms.Resize(256),\n",
        "                    transforms.CenterCrop(image_size),\n",
        "                    transforms.RandomRotation(10),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                         [0.229, 0.224, 0.225])\n",
        "                ])\n",
        "            ]\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown phase: {phase}\")\n",
        "\n",
        "\n",
        "class DatasetManager:\n",
        "    \"\"\"Class to handle dataset loading, splits, and dataloaders.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def load_dataset(data_path):\n",
        "        if not os.path.exists(data_path):\n",
        "            raise FileNotFoundError(f\"Data path not found: {data_path}\")\n",
        "        return data_path\n",
        "\n",
        "    @staticmethod\n",
        "    def create_dataset_splits(data_path, image_size):\n",
        "        tfms = {\n",
        "            'train': DataTransforms.get_transforms(image_size, 'train'),\n",
        "            'val': DataTransforms.get_transforms(image_size, 'val'),\n",
        "            'test': DataTransforms.get_transforms(image_size, 'test')\n",
        "        }\n",
        "        return {k: datasets.ImageFolder(os.path.join(data_path, k), tfms[k])\n",
        "                for k in ['train', 'val', 'test']}\n",
        "\n",
        "    @staticmethod\n",
        "    def create_dataloaders(image_datasets, batch_size):\n",
        "        loaders = {k: DataLoader(image_datasets[k], batch_size,\n",
        "                                 shuffle=(k == 'train'), num_workers=2)\n",
        "                   for k in ['train', 'val', 'test']}\n",
        "        sizes = {k: len(image_datasets[k]) for k in loaders}\n",
        "        classes = image_datasets['train'].classes\n",
        "        return loaders, sizes, classes\n",
        "\n",
        "    @staticmethod\n",
        "    def prepare_metadata(image_datasets):\n",
        "        meta = {}\n",
        "        for split, ds in image_datasets.items():\n",
        "            meta[split] = [\n",
        "                {\n",
        "                    'filepath': p,\n",
        "                    'filename': os.path.basename(p),\n",
        "                    'label': y,\n",
        "                    'class_name': c,\n",
        "                    'site_id': f\"site_{random.randint(1,5)}\"\n",
        "                }\n",
        "                for p, y in ds.samples\n",
        "                for c, i in ds.class_to_idx.items() if i == y\n",
        "            ]\n",
        "        path = os.path.join(CFG.OUTPUT_DIR, \"metadata.json\")\n",
        "        json.dump(meta, open(path, \"w\"), indent=2)\n",
        "        return meta\n",
        "\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<div style='background:#020617;padding:10px;border-radius:8px;\"\n",
        "             \"color:#a5b4fc;font-family:Segoe UI'>\"\n",
        "             \" <b>Data handling & transforms ready</b></div>\"))\n"
      ],
      "metadata": {
        "id": "_4xFd_ejBdYy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6db87903-a832-4ff0-eebf-d3bdcc3e3571"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:10px;border-radius:8px;color:#a5b4fc;font-family:Segoe UI'> <b>Data handling & transforms ready</b></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION 4: MODEL ARCHITECTURE"
      ],
      "metadata": {
        "id": "fVry0jwfBoU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hybrid CNNâ€“Transformer model\n",
        "class HybridModel(nn.Module):\n",
        "    \"\"\"EfficientNetV2 backbone + Transformer head.\"\"\"\n",
        "\n",
        "    def __init__(self, cnn_model_name, num_classes, d_model,\n",
        "                 nhead, num_encoder_layers, dim_feedforward, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = timm.create_model(\n",
        "            cnn_model_name, pretrained=True,\n",
        "            features_only=True, out_indices=[-1]\n",
        "        )\n",
        "\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))\n",
        "        enc = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout, batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            enc, num_layers=num_encoder_layers\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.backbone(x)[0]\n",
        "        b = feats.size(0)\n",
        "        seq = feats.flatten(2).permute(0, 2, 1)\n",
        "        seq = torch.cat((self.cls_token.expand(b, -1, -1), seq), 1)\n",
        "        out = self.transformer_encoder(seq)[:, 0]\n",
        "        return self.classifier(out)\n",
        "\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<div style='background:#020617;padding:10px;border-radius:8px;\"\n",
        "             \"color:#facc15;font-family:Segoe UI'>\"\n",
        "             \" <b>Hybrid CNNâ€“Transformer model ready</b></div>\"))\n"
      ],
      "metadata": {
        "id": "KtwJQ073BpPN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "52f19154-48d8-4a30-a6e5-3c28a0e4956d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:10px;border-radius:8px;color:#facc15;font-family:Segoe UI'> <b>Hybrid CNNâ€“Transformer model ready</b></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION 5: MODEL UTILITIES"
      ],
      "metadata": {
        "id": "wBS8uOBQBrG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model utilities\n",
        "class ModelUtils:\n",
        "    \"\"\"Utility functions for model operations.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def freeze_backbone(model):\n",
        "        for p in model.backbone.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "    @staticmethod\n",
        "    def unfreeze_backbone(model):\n",
        "        for p in model.backbone.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "    @staticmethod\n",
        "    def initialize_weights(model):\n",
        "        for m in model.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None: nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.LayerNorm):\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "                nn.init.constant_(m.weight, 1.0)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_loss_function(loss_type='cross_entropy'):\n",
        "        return nn.CrossEntropyLoss()\n",
        "\n",
        "    @staticmethod\n",
        "    def get_optimizer(model, learning_rate, weight_decay=1e-5):\n",
        "        return optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_lr_scheduler(optimizer, scheduler_type='cosine', epochs=8):\n",
        "        if scheduler_type == 'cosine':\n",
        "            return optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
        "        elif scheduler_type == 'reduce_on_plateau':\n",
        "            return optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
        "        return optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "    @staticmethod\n",
        "    def save_checkpoint(model, optimizer, epoch, val_acc, path):\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_acc': val_acc\n",
        "        }, path)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_best_model(model, checkpoint_path):\n",
        "        ckpt = torch.load(checkpoint_path)\n",
        "        model.load_state_dict(ckpt['model_state_dict'])\n",
        "        return model\n",
        "\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<div style='background:#020617;padding:10px;border-radius:8px;\"\n",
        "             \"color:#fda4af;font-family:Segoe UI'>\"\n",
        "             \" <b>Model utilities ready</b></div>\"))\n"
      ],
      "metadata": {
        "id": "ojb0u3_TBsL-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ae54d27c-f612-473a-f4c8-02574b6f12b2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:10px;border-radius:8px;color:#fda4af;font-family:Segoe UI'> <b>Model utilities ready</b></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION 6: TRAINING & EVALUATION LOGIC"
      ],
      "metadata": {
        "id": "JropSryyBuTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainingUtils:\n",
        "    \"\"\"Utility functions for training and evaluation.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "        model.train()\n",
        "        run_loss, correct, total = 0.0, 0, 0\n",
        "        bar = tqdm(dataloader, desc=\"Training\", unit=\"batch\")\n",
        "\n",
        "        for x, y in bar:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            run_loss += loss.item() * x.size(0)\n",
        "            preds = out.argmax(1)\n",
        "            correct += (preds == y).sum()\n",
        "            total += y.size(0)\n",
        "\n",
        "            bar.set_postfix(loss=loss.item(),\n",
        "                            acc=f\"{(correct.double()/total):.4f}\")\n",
        "\n",
        "        return run_loss/total, (correct.double()/total).item()\n",
        "\n",
        "    @staticmethod\n",
        "    def evaluate(model, dataloader, criterion, device, split='Validation'):\n",
        "        model.eval()\n",
        "        run_loss, y_true, y_pred, y_prob = 0.0, [], [], []\n",
        "        bar = tqdm(dataloader, desc=split, unit=\"batch\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x, y in bar:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                out = model(x)\n",
        "                loss = criterion(out, y)\n",
        "\n",
        "                run_loss += loss.item() * x.size(0)\n",
        "                preds = out.argmax(1)\n",
        "                probs = torch.softmax(out, 1)[:, 1]\n",
        "\n",
        "                y_true.extend(y.cpu().numpy())\n",
        "                y_pred.extend(preds.cpu().numpy())\n",
        "                y_prob.extend(probs.cpu().numpy())\n",
        "\n",
        "        return run_loss/len(y_true), accuracy_score(y_true, y_pred), y_true, y_pred, y_prob\n",
        "\n",
        "    @staticmethod\n",
        "    def test_inference(model, loader, criterion, device):\n",
        "        return TrainingUtils.evaluate(model, loader, criterion, device, split=\"Test\")\n",
        "\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<div style='background:#020617;padding:10px;border-radius:8px;\"\n",
        "             \"color:#34d399;font-family:Segoe UI'>\"\n",
        "             \"<b>Training & evaluation logic ready</b></div>\"))\n"
      ],
      "metadata": {
        "id": "vYZ7_TAiBvPe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "58a74a8f-f015-4f18-db18-c66718f9473f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:10px;border-radius:8px;color:#34d399;font-family:Segoe UI'><b>Training & evaluation logic ready</b></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION 7: METRICS & VISUALIZATION"
      ],
      "metadata": {
        "id": "xxe6UvWdBxnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MetricsAndVisualization:\n",
        "    \"\"\"Class for computing metrics and creating visualizations.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_metrics(labels, preds, probs):\n",
        "        accuracy = accuracy_score(labels, preds)\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "            labels, preds, average='binary'\n",
        "        )\n",
        "        auc = roc_auc_score(labels, probs)\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'auc': auc\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_curves(history, test_acc=None, test_auc=None):\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "        ax1.plot(history['train_acc'], label='Train Accuracy', lw=2, marker='o')\n",
        "        ax1.plot(history['val_acc'], label='Validation Accuracy', lw=2, marker='o')\n",
        "        if test_acc is not None:\n",
        "            ax1.axhline(test_acc, ls='--', lw=2, label=f'Test Acc: {test_acc:.4f}')\n",
        "        ax1.set_title('Accuracy over Epochs')\n",
        "        ax1.legend(); ax1.grid(True, ls='--', alpha=0.6)\n",
        "\n",
        "        ax2.plot(history['train_loss'], label='Train Loss', lw=2, marker='o')\n",
        "        ax2.plot(history['val_loss'], label='Validation Loss', lw=2, marker='o')\n",
        "        ax2.set_title('Loss over Epochs')\n",
        "        ax2.legend(); ax2.grid(True, ls='--', alpha=0.6)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(CFG.OUTPUT_DIR, 'training_curves.png'))\n",
        "        plt.show()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_confusion_matrix(labels, preds, class_names):\n",
        "        cm = confusion_matrix(labels, preds)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=class_names, yticklabels=class_names)\n",
        "        plt.xlabel('Predicted'); plt.ylabel('True')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.savefig(os.path.join(CFG.OUTPUT_DIR, 'confusion_matrix.png'))\n",
        "        plt.show()\n",
        "\n",
        "    @staticmethod\n",
        "    def analyze_predictions(model, dataloader, class_names, device, num_examples=5):\n",
        "        model.eval()\n",
        "        preds, labels, probs, imgs = [], [], [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x, y in dataloader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                out = model(x)\n",
        "                p = torch.softmax(out, 1)\n",
        "                preds.extend(out.argmax(1).cpu().numpy())\n",
        "                labels.extend(y.cpu().numpy())\n",
        "                probs.extend(p.cpu().numpy())\n",
        "                imgs.extend(x.cpu())\n",
        "\n",
        "        preds, labels, probs = map(np.array, (preds, labels, probs))\n",
        "\n",
        "        for tag, idxs, color in [\n",
        "            (\"Correct\", np.where(preds == labels)[0], \"green\"),\n",
        "            (\"Incorrect\", np.where(preds != labels)[0], \"red\")\n",
        "        ]:\n",
        "            for i, idx in enumerate(np.random.choice(idxs, min(num_examples, len(idxs)), False)):\n",
        "                img = imgs[idx].permute(1, 2, 0).numpy()\n",
        "                img = np.clip(\n",
        "                    img * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406], 0, 1\n",
        "                )\n",
        "                plt.figure(figsize=(4, 4))\n",
        "                plt.imshow(img)\n",
        "                plt.title(f\"{tag}\\nTrue: {class_names[labels[idx]]} | \"\n",
        "                          f\"Pred: {class_names[preds[idx]]} \"\n",
        "                          f\"({probs[idx, preds[idx]]:.2f})\",\n",
        "                          color=color)\n",
        "                plt.axis('off')\n",
        "                plt.savefig(os.path.join(CFG.OUTPUT_DIR, f'{tag.lower()}_{i}.png'))\n",
        "                plt.show()\n",
        "\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<div style='background:#020617;padding:10px;border-radius:8px;\"\n",
        "             \"color:#60a5fa;font-family:Segoe UI'>\"\n",
        "             \"ğŸ“Š <b>Metrics & visualization utilities ready</b></div>\"))\n"
      ],
      "metadata": {
        "id": "GjrJ08xZBytF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fbd79cad-5a12-44ee-9f8f-9874fed95274"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:10px;border-radius:8px;color:#60a5fa;font-family:Segoe UI'>ğŸ“Š <b>Metrics & visualization utilities ready</b></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION 8: GRAD-CAM IMPLEMENTATION"
      ],
      "metadata": {
        "id": "0oA1LXxnB1Gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GradCAM:\n",
        "    \"\"\"\n",
        "    Gradient-weighted Class Activation Mapping (Grad-CAM).\n",
        "    Hooks into the model backbone to visualize class-specific regions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: nn.Module, target_layer_name: str):\n",
        "        self.model = model\n",
        "        self.target_layer = self._find_target_layer(target_layer_name)\n",
        "        self.feature_maps, self.gradients = {}, {}\n",
        "        self._register_hooks()\n",
        "\n",
        "    def _find_target_layer(self, name: str):\n",
        "        modules = dict(self.model.backbone.named_modules())\n",
        "\n",
        "        if name in modules and isinstance(modules[name], nn.Conv2d):\n",
        "            return modules[name]\n",
        "\n",
        "        for _, m in reversed(modules.items()):\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                return m\n",
        "\n",
        "        raise ValueError(\"No Conv2d layer found for Grad-CAM.\")\n",
        "\n",
        "    def _register_hooks(self):\n",
        "        self.target_layer.register_forward_hook(\n",
        "            lambda m, i, o: self.feature_maps.update({0: o.detach()})\n",
        "        )\n",
        "        self.target_layer.register_backward_hook(\n",
        "            lambda m, gi, go: self.gradients.update({0: go[0].detach()})\n",
        "        )\n",
        "\n",
        "    def __call__(self, input_tensor: torch.Tensor, target_category: int) -> np.ndarray:\n",
        "        self.model.zero_grad()\n",
        "        output = self.model(input_tensor)\n",
        "        output[:, target_category].backward(retain_graph=True)\n",
        "\n",
        "        fmap = self.feature_maps[0]\n",
        "        grad = self.gradients[0]\n",
        "\n",
        "        weights = grad.mean(dim=(2, 3), keepdim=True)\n",
        "        cam = F.relu((weights * fmap).sum(dim=1))\n",
        "\n",
        "        heatmap = cam.squeeze(0).cpu().numpy()\n",
        "        heatmap /= np.max(heatmap)\n",
        "        return cv2.resize(heatmap,\n",
        "                          (input_tensor.shape[2], input_tensor.shape[3]))\n",
        "\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<div style='background:#020617;padding:10px;border-radius:8px;\"\n",
        "             \"color:#f472b6;font-family:Segoe UI'>\"\n",
        "             \"<b>Grad-CAM module ready</b></div>\"))\n"
      ],
      "metadata": {
        "id": "1I2ojFo-B2Mf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "40788d22-d7fd-4486-98d0-d9e11f8361b2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:10px;border-radius:8px;color:#f472b6;font-family:Segoe UI'><b>Grad-CAM module ready</b></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION 9: GRAD-CAM VISUALIZATION UTILITIES"
      ],
      "metadata": {
        "id": "wfN4WIyoB4wF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grad-CAM visualization helpers\n",
        "def visualize_grad_cam(original_image: np.ndarray,\n",
        "                       heatmap: np.ndarray,\n",
        "                       title: str,\n",
        "                       save_path=None):\n",
        "\n",
        "    img = (original_image * 255).astype(np.uint8)\n",
        "    heat = cv2.applyColorMap((255 * heatmap).astype(np.uint8), cv2.COLORMAP_JET)\n",
        "    heat = cv2.cvtColor(heat, cv2.COLOR_BGR2RGB)\n",
        "    overlay = cv2.addWeighted(img, 0.6, heat, 0.4, 0)\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax[0].imshow(original_image); ax[0].set_title(f\"Original: {title}\"); ax[0].axis(\"off\")\n",
        "    ax[1].imshow(overlay); ax[1].set_title(f\"Grad-CAM: {title}\"); ax[1].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_path: plt.savefig(save_path)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "class GradCAMUtils:\n",
        "    \"\"\"Utility class for Grad-CAM generation.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_and_save_gradcam_samples(model, dataloader,\n",
        "                                          class_names, device,\n",
        "                                          num_samples=5):\n",
        "\n",
        "        cam = GradCAM(model, target_layer_name=\"features.8\")\n",
        "        idxs = np.random.choice(len(dataloader.dataset),\n",
        "                                num_samples, replace=False)\n",
        "\n",
        "        for i, idx in enumerate(idxs):\n",
        "            img, label = dataloader.dataset[idx]\n",
        "            img_t = img.unsqueeze(0).to(device)\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                out = model(img_t)\n",
        "                prob = F.softmax(out, 1)\n",
        "                pred = prob.argmax(1).item()\n",
        "\n",
        "            heatmap = cam(img_t, pred)\n",
        "\n",
        "            img_np = img_t.squeeze(0).cpu().numpy().transpose(1, 2, 0)\n",
        "            img_np = np.clip(img_np * [0.229, 0.224, 0.225]\n",
        "                              + [0.485, 0.456, 0.406], 0, 1)\n",
        "\n",
        "            title = (f\"Pred: {class_names[pred]} \"\n",
        "                     f\"({prob[0, pred]:.2f}) | \"\n",
        "                     f\"True: {class_names[label]}\")\n",
        "\n",
        "            visualize_grad_cam(\n",
        "                img_np, heatmap, title,\n",
        "                os.path.join(CFG.OUTPUT_DIR, f\"gradcam_{i}.png\")\n",
        "            )\n",
        "\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<div style='background:#020617;padding:10px;border-radius:8px;\"\n",
        "             \"color:#fb7185;font-family:Segoe UI'>\"\n",
        "             \"<b>Grad-CAM visualization utilities ready</b></div>\"))\n"
      ],
      "metadata": {
        "id": "fE253qxHB6Em",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6b487679-97c0-4be0-90e6-54aa975678a1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:10px;border-radius:8px;color:#fb7185;font-family:Segoe UI'><b>Grad-CAM visualization utilities ready</b></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION 10: ADVANCED TECHNIQUES"
      ],
      "metadata": {
        "id": "M-F1Ewu-B8c1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdvancedTechniques:\n",
        "    \"\"\"Advanced training, validation, and optimization techniques.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def k_fold_cross_validation(data_path, image_size, batch_size, k_folds=2):\n",
        "        full_ds = datasets.ImageFolder(\n",
        "            os.path.join(data_path, 'train'),\n",
        "            transform=DataTransforms.get_transforms(image_size, 'train')\n",
        "        )\n",
        "        labels = [y for _, y in full_ds.samples]\n",
        "        skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=CFG.SEED)\n",
        "\n",
        "        results = []\n",
        "        for fold, (tr, va) in enumerate(skf.split(np.zeros(len(labels)), labels)):\n",
        "            tr_loader = DataLoader(Subset(full_ds, tr), batch_size, True, num_workers=2)\n",
        "            va_loader = DataLoader(Subset(full_ds, va), batch_size, False, num_workers=2)\n",
        "\n",
        "            model = HybridModel(\n",
        "                CFG.MODEL_NAME, CFG.NUM_CLASSES, CFG.D_MODEL,\n",
        "                CFG.NHEAD, CFG.NUM_ENCODER_LAYERS,\n",
        "                CFG.DIM_FEEDFORWARD, CFG.DROPOUT\n",
        "            ).to(CFG.device)\n",
        "\n",
        "            ModelUtils.initialize_weights(model)\n",
        "            crit = ModelUtils.get_loss_function()\n",
        "            opt = ModelUtils.get_optimizer(model, CFG.LEARNING_RATE)\n",
        "            sch = ModelUtils.get_lr_scheduler(opt, epochs=CFG.EPOCHS)\n",
        "\n",
        "            best = 0.0\n",
        "            for _ in range(CFG.EPOCHS):\n",
        "                TrainingUtils.train_one_epoch(model, tr_loader, crit, opt, CFG.device)\n",
        "                _, acc, _, _, _ = TrainingUtils.evaluate(\n",
        "                    model, va_loader, crit, CFG.device\n",
        "                )\n",
        "                sch.step()\n",
        "                if acc > best:\n",
        "                    best = acc\n",
        "                    torch.save(\n",
        "                        model.state_dict(),\n",
        "                        os.path.join(CFG.OUTPUT_DIR, f'fold_{fold+1}_best.pth')\n",
        "                    )\n",
        "\n",
        "            results.append({'fold': fold + 1, 'best_val_acc': best})\n",
        "\n",
        "        pd.DataFrame(results).to_csv(\n",
        "            os.path.join(CFG.OUTPUT_DIR, 'kfold_results.csv'), index=False\n",
        "        )\n",
        "        return results\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_kfold_results(fold_results):\n",
        "        folds = [f\"Fold {r['fold']}\" for r in fold_results]\n",
        "        accs = [r['best_val_acc'] for r in fold_results]\n",
        "\n",
        "        avg, std = np.mean(accs), np.std(accs)\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        bars = plt.bar(folds, accs, yerr=std, capsize=5, alpha=0.7)\n",
        "        plt.axhline(avg, ls='--', color='red', label=f'Avg: {avg:.4f} Â± {std:.4f}')\n",
        "        for b, a in zip(bars, accs):\n",
        "            plt.text(b.get_x()+b.get_width()/2, a+std, f'{a:.4f}',\n",
        "                     ha='center', va='bottom')\n",
        "        plt.legend(); plt.grid(True, ls='--', alpha=0.6)\n",
        "        plt.savefig(os.path.join(CFG.OUTPUT_DIR, 'kfold_results_plot.png'))\n",
        "        plt.show()\n",
        "\n",
        "    @staticmethod\n",
        "    def objective(trial, train_loader, val_loader):\n",
        "        model = HybridModel(\n",
        "            CFG.MODEL_NAME, CFG.NUM_CLASSES, CFG.D_MODEL,\n",
        "            trial.suggest_categorical('nhead', [4, 8, 16]),\n",
        "            CFG.NUM_ENCODER_LAYERS, CFG.DIM_FEEDFORWARD,\n",
        "            trial.suggest_float('dropout', 0.1, 0.5)\n",
        "        ).to(CFG.device)\n",
        "\n",
        "        opt = ModelUtils.get_optimizer(\n",
        "            model,\n",
        "            trial.suggest_float('lr', 1e-5, 1e-3, log=True),\n",
        "            trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)\n",
        "        )\n",
        "        crit = ModelUtils.get_loss_function()\n",
        "\n",
        "        best = 0.0\n",
        "        for _ in range(2):\n",
        "            TrainingUtils.train_one_epoch(model, train_loader, crit, opt, CFG.device)\n",
        "            _, acc, _, _, _ = TrainingUtils.evaluate(\n",
        "                model, val_loader, crit, CFG.device\n",
        "            )\n",
        "            best = max(best, acc)\n",
        "        return best\n",
        "\n",
        "    @staticmethod\n",
        "    def hyperparameter_tuning(train_loader, val_loader, n_trials=2):\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        study.optimize(\n",
        "            lambda t: AdvancedTechniques.objective(t, train_loader, val_loader),\n",
        "            n_trials=n_trials\n",
        "        )\n",
        "        json.dump(\n",
        "            study.best_params,\n",
        "            open(os.path.join(CFG.OUTPUT_DIR, 'best_hyperparams.json'), 'w'),\n",
        "            indent=2\n",
        "        )\n",
        "        return study.best_params\n",
        "\n",
        "    @staticmethod\n",
        "    def evaluate_model_calibration(model, dataloader, device):\n",
        "        calibrator = CalibrationError(\n",
        "            task=\"multiclass\", num_classes=CFG.NUM_CLASSES\n",
        "        ).to(device)\n",
        "\n",
        "        preds, labels, probs = [], [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for x, y in dataloader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                out = model(x)\n",
        "                p = torch.softmax(out, 1)\n",
        "                preds.extend(out.argmax(1).cpu())\n",
        "                labels.extend(y.cpu())\n",
        "                probs.extend(p.cpu())\n",
        "\n",
        "        ece = calibrator(torch.stack(probs).to(device),\n",
        "                         torch.tensor(labels).to(device))\n",
        "        return ece.item()\n",
        "\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<div style='background:#020617;padding:10px;border-radius:8px;\"\n",
        "             \"color:#22d3ee;font-family:Segoe UI'>\"\n",
        "             \"<b>Advanced techniques module ready</b></div>\"))\n"
      ],
      "metadata": {
        "id": "Q0pqtCUsB9oV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8e6d8b1d-8338-43cd-9021-be4735e28836"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:10px;border-radius:8px;color:#22d3ee;font-family:Segoe UI'><b>Advanced techniques module ready</b></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "def stage(title, subtitle=\"\", color=\"#38bdf8\"):\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style=\"\n",
        "        background:linear-gradient(135deg,#020617,#020617);\n",
        "        border-left:6px solid {color};\n",
        "        padding:14px 18px;\n",
        "        border-radius:10px;\n",
        "        margin:10px 0;\n",
        "        font-family:Segoe UI;\n",
        "        color:#e5e7eb;\n",
        "        box-shadow:0 4px 14px #0006\">\n",
        "        <h3 style=\"margin:0;color:{color}\">{title}</h3>\n",
        "        <div style=\"opacity:.85\">{subtitle}</div>\n",
        "    </div>\n",
        "    \"\"\"))\n"
      ],
      "metadata": {
        "id": "Vu18zehHve5f"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION 11: MAIN EXECUTION PIPELINE"
      ],
      "metadata": {
        "id": "D9s-hG7CB_8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "def card(msg, color=\"#38bdf8\"):\n",
        "    display(HTML(\n",
        "        f\"<div style='background:#020617;padding:12px;border-radius:10px;\"\n",
        "        f\"color:{color};font-family:Segoe UI;margin-bottom:6px'>\"\n",
        "        f\"<b>{msg}</b></div>\"\n",
        "    ))\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution pipeline\"\"\"\n",
        "\n",
        "    # ğŸš€ START\n",
        "    card(\"ğŸš€ Starting Bone Fracture Detection Pipeline\", \"#22d3ee\")\n",
        "\n",
        "    # =========================\n",
        "    # Phase 1: Data Preparation\n",
        "    # =========================\n",
        "    card(\"ğŸ“ Phase 1: Data Preparation\", \"#a5b4fc\")\n",
        "\n",
        "    data_path = DatasetManager.load_dataset(CFG.DATA_PATH)\n",
        "    image_datasets = DatasetManager.create_dataset_splits(data_path, CFG.IMAGE_SIZE)\n",
        "    dataloaders, dataset_sizes, class_names = DatasetManager.create_dataloaders(\n",
        "        image_datasets, CFG.BATCH_SIZE\n",
        "    )\n",
        "    DatasetManager.prepare_metadata(image_datasets)\n",
        "\n",
        "    card(\n",
        "        f\"âœ… Data ready | \"\n",
        "        f\"Train: {dataset_sizes['train']} | \"\n",
        "        f\"Val: {dataset_sizes['val']} | \"\n",
        "        f\"Test: {dataset_sizes['test']} | \"\n",
        "        f\"Classes: {class_names}\",\n",
        "        \"#34d399\"\n",
        "    )\n",
        "\n",
        "    # =========================\n",
        "    # Phase 2: Model Setup\n",
        "    # =========================\n",
        "    card(\"ğŸ§  Phase 2: Model Construction\", \"#facc15\")\n",
        "\n",
        "    model = HybridModel(\n",
        "        CFG.MODEL_NAME, CFG.NUM_CLASSES, CFG.D_MODEL,\n",
        "        CFG.NHEAD, CFG.NUM_ENCODER_LAYERS,\n",
        "        CFG.DIM_FEEDFORWARD, CFG.DROPOUT\n",
        "    ).to(CFG.device)\n",
        "\n",
        "    ModelUtils.initialize_weights(model)\n",
        "    ModelUtils.freeze_backbone(model)\n",
        "\n",
        "    card(f\"âœ… Model initialized on {CFG.device}\", \"#34d399\")\n",
        "\n",
        "    # =========================\n",
        "    # Phase 3: Training\n",
        "    # =========================\n",
        "    card(\"ğŸ”¥ Phase 3: Training Pipeline\", \"#fb7185\")\n",
        "\n",
        "    criterion = ModelUtils.get_loss_function()\n",
        "    optimizer = ModelUtils.get_optimizer(model, CFG.LEARNING_RATE)\n",
        "    scheduler = ModelUtils.get_lr_scheduler(optimizer, epochs=CFG.EPOCHS)\n",
        "\n",
        "    history = dict(train_loss=[], train_acc=[], val_loss=[], val_acc=[])\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    for epoch in range(CFG.EPOCHS):\n",
        "        card(f\"ğŸ”„ Epoch {epoch+1}/{CFG.EPOCHS}\", \"#60a5fa\")\n",
        "\n",
        "        # ğŸ”“ Unfreeze backbone halfway\n",
        "        if epoch == CFG.EPOCHS // 2:\n",
        "            card(\"ğŸ”“ Unfreezing backbone + LR decay\", \"#fde047\")\n",
        "            ModelUtils.unfreeze_backbone(model)\n",
        "            optimizer = ModelUtils.get_optimizer(model, CFG.LEARNING_RATE * 0.1)\n",
        "            scheduler = ModelUtils.get_lr_scheduler(\n",
        "                optimizer, epochs=CFG.EPOCHS - epoch\n",
        "            )\n",
        "\n",
        "        # ğŸ”µ TRAIN (BLUE BAR)\n",
        "        train_loss, train_acc = TrainingUtils.train_one_epoch(\n",
        "            model,\n",
        "            dataloaders['train'],\n",
        "            criterion,\n",
        "            optimizer,\n",
        "            CFG.device\n",
        "        )\n",
        "\n",
        "        # ğŸŸ¢ VALIDATION (GREEN BAR)\n",
        "        val_loss, val_acc, _, _, _ = TrainingUtils.evaluate(\n",
        "            model,\n",
        "            dataloaders['val'],\n",
        "            criterion,\n",
        "            CFG.device,\n",
        "            split=\"Validation\"\n",
        "        )\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        card(\n",
        "            f\"ğŸ“Š Train Acc: {train_acc:.4f} | \"\n",
        "            f\"Val Acc: {val_acc:.4f} | \"\n",
        "            f\"Train Loss: {train_loss:.4f} | \"\n",
        "            f\"Val Loss: {val_loss:.4f}\",\n",
        "            \"#22d3ee\"\n",
        "        )\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            ModelUtils.save_checkpoint(\n",
        "                model, optimizer, epoch, val_acc,\n",
        "                os.path.join(CFG.OUTPUT_DIR, \"best_model.pth\")\n",
        "            )\n",
        "            card(f\"ğŸ’¾ New best model saved (Val Acc: {val_acc:.4f})\", \"#4ade80\")\n",
        "\n",
        "    # =========================\n",
        "    # Phase 4: Evaluation\n",
        "    # =========================\n",
        "    card(\"ğŸ“ˆ Phase 4: Model Evaluation\", \"#c084fc\")\n",
        "\n",
        "    best_model = HybridModel(\n",
        "        CFG.MODEL_NAME, CFG.NUM_CLASSES, CFG.D_MODEL,\n",
        "        CFG.NHEAD, CFG.NUM_ENCODER_LAYERS,\n",
        "        CFG.DIM_FEEDFORWARD, CFG.DROPOUT\n",
        "    ).to(CFG.device)\n",
        "\n",
        "    best_model = ModelUtils.load_best_model(\n",
        "        best_model, os.path.join(CFG.OUTPUT_DIR, \"best_model.pth\")\n",
        "    )\n",
        "\n",
        "    test_loss, test_acc, labels, preds, probs = TrainingUtils.test_inference(\n",
        "        best_model, dataloaders['test'], criterion, CFG.device\n",
        "    )\n",
        "\n",
        "    metrics = MetricsAndVisualization.compute_metrics(labels, preds, probs)\n",
        "\n",
        "    card(\n",
        "        f\"âœ… Test Results | \"\n",
        "        f\"Acc: {metrics['accuracy']:.4f} | \"\n",
        "        f\"Prec: {metrics['precision']:.4f} | \"\n",
        "        f\"Recall: {metrics['recall']:.4f} | \"\n",
        "        f\"F1: {metrics['f1']:.4f} | \"\n",
        "        f\"AUC: {metrics['auc']:.4f}\",\n",
        "        \"#34d399\"\n",
        "    )\n",
        "\n",
        "    MetricsAndVisualization.plot_curves(history, test_acc, metrics['auc'])\n",
        "    MetricsAndVisualization.plot_confusion_matrix(labels, preds, class_names)\n",
        "    MetricsAndVisualization.analyze_predictions(\n",
        "        best_model, dataloaders['test'], class_names, CFG.device\n",
        "    )\n",
        "\n",
        "    # =========================\n",
        "    # Phase 4.5: Grad-CAM\n",
        "    # =========================\n",
        "    card(\"ğŸ”¥ Phase 4.5: Grad-CAM Visualization\", \"#fb7185\")\n",
        "    GradCAMUtils.generate_and_save_gradcam_samples(\n",
        "        best_model, dataloaders['test'],\n",
        "        class_names, CFG.device, num_samples=5\n",
        "    )\n",
        "\n",
        "    # =========================\n",
        "    # Phase 5: Robustness\n",
        "    # =========================\n",
        "    card(\"ğŸ§ª Phase 5: Robustness & Optimization\", \"#22d3ee\")\n",
        "\n",
        "    folds = AdvancedTechniques.k_fold_cross_validation(\n",
        "        CFG.DATA_PATH, CFG.IMAGE_SIZE, CFG.BATCH_SIZE\n",
        "    )\n",
        "    AdvancedTechniques.plot_kfold_results(folds)\n",
        "\n",
        "    best_params = AdvancedTechniques.hyperparameter_tuning(\n",
        "        dataloaders['train'], dataloaders['val']\n",
        "    )\n",
        "\n",
        "    card(f\"âš™ï¸ Best Hyperparameters: {best_params}\", \"#a7f3d0\")\n",
        "\n",
        "    ece = AdvancedTechniques.evaluate_model_calibration(\n",
        "        best_model, dataloaders['test'], CFG.device\n",
        "    )\n",
        "    card(f\"ğŸ“ Calibration ECE: {ece:.4f}\", \"#fda4af\")\n",
        "\n",
        "    card(\"ğŸ‰ Pipeline completed successfully!\", \"#4ade80\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "Z0Q78ZkGCBhO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "584dfa74-30b7-46ac-990a-0abaa37307bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#22d3ee;font-family:Segoe UI;margin-bottom:6px'><b>ğŸš€ Starting Bone Fracture Detection Pipeline</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#a5b4fc;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ“ Phase 1: Data Preparation</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#34d399;font-family:Segoe UI;margin-bottom:6px'><b>âœ… Data ready | Train: 1701 | Val: 212 | Test: 214 | Classes: ['fracture', 'normal']</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#facc15;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ§  Phase 2: Model Construction</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:timm.models._builder:Unexpected keys (bn2.num_batches_tracked, bn2.bias, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#34d399;font-family:Segoe UI;margin-bottom:6px'><b>âœ… Model initialized on cuda:0</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#fb7185;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ”¥ Phase 3: Training Pipeline</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#60a5fa;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ”„ Epoch 1/30</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/213 [00:28<00:00,  7.55batch/s, acc=0.9347, loss=0.377]\n",
            "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:03<00:00,  7.58batch/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#22d3ee;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ“Š Train Acc: 0.9347 | Val Acc: 0.9528 | Train Loss: 0.2674 | Val Loss: 0.1721</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#4ade80;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ’¾ New best model saved (Val Acc: 0.9528)</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#60a5fa;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ”„ Epoch 2/30</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/213 [00:30<00:00,  7.01batch/s, acc=0.9459, loss=0.309]\n",
            "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:02<00:00, 11.11batch/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#22d3ee;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ“Š Train Acc: 0.9459 | Val Acc: 0.8208 | Train Loss: 0.1589 | Val Loss: 0.4024</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#60a5fa;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ”„ Epoch 3/30</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/213 [00:28<00:00,  7.52batch/s, acc=0.9547, loss=0.638]\n",
            "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:02<00:00, 10.53batch/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#22d3ee;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ“Š Train Acc: 0.9547 | Val Acc: 0.8443 | Train Loss: 0.1313 | Val Loss: 0.3098</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#60a5fa;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ”„ Epoch 4/30</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/213 [00:28<00:00,  7.41batch/s, acc=0.9559, loss=0.114]\n",
            "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:02<00:00,  9.12batch/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#22d3ee;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ“Š Train Acc: 0.9559 | Val Acc: 0.7783 | Train Loss: 0.1349 | Val Loss: 0.5002</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#60a5fa;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ”„ Epoch 5/30</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/213 [00:28<00:00,  7.47batch/s, acc=0.9624, loss=0.0597]\n",
            "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:02<00:00, 11.19batch/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#22d3ee;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ“Š Train Acc: 0.9624 | Val Acc: 0.9009 | Train Loss: 0.0997 | Val Loss: 0.2189</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#60a5fa;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ”„ Epoch 6/30</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/213 [00:28<00:00,  7.54batch/s, acc=0.9694, loss=0.351]\n",
            "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:02<00:00, 11.31batch/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#22d3ee;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ“Š Train Acc: 0.9694 | Val Acc: 0.9104 | Train Loss: 0.0876 | Val Loss: 0.1891</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#60a5fa;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ”„ Epoch 7/30</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/213 [00:27<00:00,  7.66batch/s, acc=0.9683, loss=0.0693]\n",
            "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:03<00:00,  8.59batch/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#22d3ee;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ“Š Train Acc: 0.9683 | Val Acc: 0.8962 | Train Loss: 0.1022 | Val Loss: 0.2699</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#60a5fa;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ”„ Epoch 8/30</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/213 [00:28<00:00,  7.52batch/s, acc=0.9712, loss=0.0887]\n",
            "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:02<00:00, 10.57batch/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#22d3ee;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ“Š Train Acc: 0.9712 | Val Acc: 0.9104 | Train Loss: 0.0903 | Val Loss: 0.1898</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#60a5fa;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ”„ Epoch 9/30</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/213 [00:27<00:00,  7.65batch/s, acc=0.9788, loss=0.00836]\n",
            "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:02<00:00, 11.52batch/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#22d3ee;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ“Š Train Acc: 0.9788 | Val Acc: 0.8821 | Train Loss: 0.0672 | Val Loss: 0.3640</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#60a5fa;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ”„ Epoch 10/30</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/213 [00:27<00:00,  7.65batch/s, acc=0.9653, loss=0.00385]\n",
            "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:02<00:00, 11.52batch/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#22d3ee;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ“Š Train Acc: 0.9653 | Val Acc: 0.9387 | Train Loss: 0.0844 | Val Loss: 0.1608</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#60a5fa;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ”„ Epoch 11/30</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/213 [00:27<00:00,  7.65batch/s, acc=0.9677, loss=0.000656]\n",
            "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:02<00:00,  9.54batch/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#22d3ee;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ“Š Train Acc: 0.9677 | Val Acc: 0.9057 | Train Loss: 0.0804 | Val Loss: 0.1783</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='background:#020617;padding:12px;border-radius:10px;color:#60a5fa;font-family:Segoe UI;margin-bottom:6px'><b>ğŸ”„ Epoch 12/30</b></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 138/213 [00:18<00:08,  8.83batch/s, acc=0.9748, loss=0.156]  "
          ]
        }
      ]
    }
  ]
}